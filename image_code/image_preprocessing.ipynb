{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNga3Jbrf1pnGGvrOr9kmmi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BjtUHo0ak90","executionInfo":{"status":"ok","timestamp":1712097346071,"user_tz":-60,"elapsed":258142,"user":{"displayName":"Israt Tabassum","userId":"03898431593025995993"}},"outputId":"328e8554-b83e-4371-872d-3b2e56f3d4a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Class counts after augmentation: Counter({'1': 257, '0': 257, '2': 257, '3': 257})\n"]}],"source":["import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torchvision import datasets, transforms\n","import torchvision.transforms.functional as TF\n","from PIL import Image\n","from random import choice\n","from collections import Counter\n","from torch.utils.data import DataLoader\n","\n","from google.colab import drive\n","\n","def analyze_dataset(path):\n","    class_counts = Counter()\n","    for class_dir in os.listdir(path):\n","        class_path = os.path.join(path, class_dir)\n","        if os.path.isdir(class_path):\n","            count = len([img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","            class_counts[class_dir] = count\n","    return class_counts\n","\n","def random_transform(image):\n","    \"\"\"Apply random transformations to an image.\"\"\"\n","    image = image.convert(\"RGB\")\n","    if torch.rand(1) > 0.5:\n","        image = TF.hflip(image)\n","    if torch.rand(1) > 0.5:\n","        image = TF.vflip(image)\n","    angle = torch.randint(-30, 30, (1,)).item()\n","    image = TF.rotate(image, angle)\n","    return image\n","\n","def balance_dataset(path):\n","    class_counts = analyze_dataset(path)\n","    max_per_class = max(class_counts.values())\n","    for class_dir in os.listdir(path):\n","        class_path = os.path.join(path, class_dir)\n","        images = [img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","        while len(images) < max_per_class:\n","            img_to_copy = choice(images)\n","            img_path = os.path.join(class_path, img_to_copy)\n","            with Image.open(img_path) as img:\n","                new_img = random_transform(img)\n","                new_img_name = f\"aug_{len(images)}_{img_to_copy}\"\n","                new_img.save(os.path.join(class_path, new_img_name))\n","            images.append(new_img_name)\n","            class_counts[class_dir] += 1\n","    return class_counts\n","\n","# Mount Google Drive (specific to Google Colab)\n","drive.mount('/content/drive')\n","\n","base_path = '/content/drive/My Drive/Colab Notebooks/private-data/image/dataset'\n","classes = ['0', '1', '2', '3']  # List of class names\n","\n","\n","\n","\n","# Apply augmentation to balance dataset\n","updated_class_counts = balance_dataset(base_path)\n","print(\"Class counts after augmentation:\", updated_class_counts)\n","\n","train_path = os.path.join(base_path, 'train')\n","val_path = os.path.join(base_path, 'val')  # Validation path\n","test_path = os.path.join(base_path, 'test')\n","\n","# Create train, validation, and test directories\n","for path in [train_path, val_path, test_path]:\n","    if not os.path.exists(path):\n","        os.mkdir(path)\n","\n","# Create subdirectories for each class in train, validation, and test\n","for _class in classes:\n","    for path in [train_path, val_path, test_path]:\n","        os.makedirs(os.path.join(path, _class), exist_ok=True)\n","\n","train_size = 0.8  # 80% for training\n","\n","# Splitting and moving images\n","for _class in classes:\n","    class_dir = os.path.join(base_path, _class)\n","    images = [img for img in os.listdir(class_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    if not images:\n","        print(f\"No images found in class {_class} directory.\")\n","        continue\n","\n","    # Splitting into train and non-train (test + validation) sets\n","    train_imgs, non_train_imgs = train_test_split(images, test_size=1 - train_size, random_state=42)\n","    test_imgs, val_imgs = train_test_split(non_train_imgs, test_size=0.5, random_state=42)\n","\n","    # Move files to respective directories\n","    for img in train_imgs:\n","        shutil.move(os.path.join(class_dir, img), os.path.join(train_path, _class, img))\n","    for img in val_imgs:\n","        shutil.move(os.path.join(class_dir, img), os.path.join(val_path, _class, img))\n","    for img in test_imgs:\n","        shutil.move(os.path.join(class_dir, img), os.path.join(test_path, _class, img))\n","\n","# Define transformations for loading the datasets\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","# Load datasets\n","train_dataset = datasets.ImageFolder(train_path, transform=transform)\n","val_dataset = datasets.ImageFolder(val_path, transform=transform)\n","test_dataset = datasets.ImageFolder(test_path, transform=transform)\n","\n","# Data loaders\n","train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n","\n","\n"]}]}